# This workflow is the main workflow for regenerating the benchmarks data needed for Bowtie's UI.
# It runs all benchmarks over Bowtie's supported implementations, publishing the benchmark reports (and other auxiliary metadata) for use in the frontend.
name: Collect New Benchmark Results

on:
  workflow_dispatch:
  schedule:
    # Every Monday at 00:00 UTC
    - cron: "0 0 * * 1"

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  dialects:
    runs-on: ubuntu-latest
    outputs:
      dialects: ${{ steps.dialects-matrix.outputs.dialects }}
    steps:
      - uses: actions/checkout@v4
      - name: Collect supported dialects
        id: dialects-matrix
        run: |
          printf 'dialects=%s\n' "$(jq -c '[.[].shortName]' data/dialects.json)" >> $GITHUB_OUTPUT

  benchmark_files:
    needs: dialects
    runs-on: ubuntu-latest
    outputs:
      dialect_keyword_benchmarks: ${{ steps.keyword-benchmarks.outputs.dialect_keyword_benchmarks }}
      dialect_default_benchmarks: ${{ steps.default-benchmarks.outputs.dialect_default_benchmarks }}
    steps:
      - uses: actions/checkout@v4
      - name: Install Bowtie
        uses: ./
        with:
          version: ${{ inputs.bowtie-version }}

      - name: Collect Keyword Benchmark Files
        id: keyword-benchmarks
        run: |
          results=()
          dialects='${{ needs.dialects.outputs.dialects }}'
          dialects=$(echo $dialects | jq -r '.[]')
          results=()

          for dialect in $dialects; do
            output=$(bowtie filter-benchmarks -t keyword -D "$dialect")

            if [ -n "$output" ]; then
              while IFS= read -r line; do
                json_result=$(jq -nc --arg p "$dialect" --arg o "$line" '{ dialect: $p, benchmark: $o }')
                results+=("$json_result")
              done <<< "$output"
            fi
          done
          final_json="$(jq -sc '.' <<< "${results[@]}")"
          final_json=$(echo "$final_json" | jq -c '{ "include": . }')
          echo $final_json >> $GITHUB_STEP_SUMMARY
          echo "dialect_keyword_benchmarks=$final_json" >> $GITHUB_OUTPUT
          
          echo 

      - name: Collect Default Benchmark Files
        id: default-benchmarks
        run: |
          results=()
          dialects='${{ needs.dialects.outputs.dialects }}'
          dialects=$(echo $dialects | jq -r '.[]')
          results=()

          for dialect in $dialects; do
            output=$(bowtie filter-benchmarks -D "$dialect")

            if [ -n "$output" ]; then
              while IFS= read -r line; do
                json_result=$(jq -nc --arg p "$dialect" --arg o "$line" '{ dialect: $p, benchmark: $o }')
                results+=("$json_result")
              done <<< "$output"
            fi
          done
          final_json="$(jq -sc '.' <<< "${results[@]}")"
          final_json=$(echo "$final_json" | jq -c '{ "include": . }')
          echo $final_json >> $GITHUB_STEP_SUMMARY
          echo "dialect_default_benchmarks=$final_json" >> $GITHUB_OUTPUT

  run_keyword_benchmarks:
    needs: benchmark_files
    runs-on: ubuntu-latest
    timeout-minutes: 720
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.benchmark_files.outputs.dialect_keyword_benchmarks) }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - name: Install Bowtie
        uses: ./
        with:
          version: ${{ inputs.bowtie-version }}

      - name: Install dependencies
        run: |
          python -m pip install pyperf

      - name: Generate Benchmark Report
        run: |
          bowtie perf $(bowtie filter-implementations | sed 's/^/-i /') -b ${{ matrix.benchmark }} -D ${{ matrix.dialect }}

  run_default_benchmarks:
    needs: benchmark_files
    runs-on: ubuntu-latest
    timeout-minutes: 720
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.benchmark_files.outputs.dialect_default_benchmarks) }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'
      - name: Install Bowtie
        uses: ./
        with:
          version: ${{ inputs.bowtie-version }}

      - name: Install dependencies
        run: |
          python -m pip install pyperf

      - name: Generate Benchmark Report
        run: |
          bowtie perf $(bowtie filter-implementations | sed 's/^/-i /') -b ${{ matrix.benchmark }} -D ${{ matrix.dialect }}
